{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5r0QgccJYlA"
   },
   "source": [
    "In this coding file, we aimed to **summarize the abstract and generate supplementary descriptions** based on the paperâ€™s 'title' and 'abstract' fields, utilizing the ChatGPT-4o-mini model API. The final file is jsonl and json -> input for visualization as hover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJwY0YkHOyN5"
   },
   "source": [
    "#0) Paper filtration from raw MU scopus csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8dVMUr0Ms3B"
   },
   "outputs": [],
   "source": [
    "#Certain entries in the raw file were identified as editorial notifications rather than readable abstracts. Therefore, these records were removed from the database\n",
    "\n",
    "# this code process seperate year\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openai import OpenAI\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kx3inrh9NdzE"
   },
   "outputs": [],
   "source": [
    "df_path = '/content/MU Papers/scopus_export_2021_(Dec 12-2025).csv'\n",
    "df = pd.read_csv(df_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afjYKuaPNhZ4"
   },
   "outputs": [],
   "source": "df.dropna(subset=['Abstract'], inplace=True)\ndf.drop_duplicates(subset=['Abstract'], inplace=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSTAO5K5NjlN"
   },
   "outputs": [],
   "source": [
    "# eda data to find the cut point to clean\n",
    "visual_1 = df[df['abstract_length'] < 30][['Title', 'Abstract']]\n",
    "visual_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfFl1_wCNrFl"
   },
   "outputs": [],
   "source": [
    "#check if there any row 'Abstract' have '[No abstract available]' delete\n",
    "print(\"shape before: \", df.shape)\n",
    "df = df[df['Abstract'] != '[No abstract available]']\n",
    "print(\"shape after: \", df.shape)\n",
    "\n",
    "# delete with abstract that contain false abstract\n",
    "print(\"shape before: \", df.shape)\n",
    "df = df[df['Abstract'].str.contains('Corresponding Author') == False]\n",
    "df = df[~df['Abstract'].str.contains('Correction to:', na=False)]\n",
    "print(\"shape after: \", df.shape)\n",
    "\n",
    "#check if title have contain 'correction to:'\n",
    "df = df[df['Title'].str.contains('Correction to:') == False]\n",
    "print(\"shape after: \", df.shape)\n",
    "\n",
    "#check if there any document type that is erratum\n",
    "df = df[df['Document Type'] != 'Erratum']\n",
    "print(\"shape after: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_qIMvdjNu0V"
   },
   "outputs": [],
   "source": [
    "# save\n",
    "path_directory='/content/MU Papers/Cleaned'\n",
    "file_path = os.path.join(path_directory, '2021_cleaned_data.csv')\n",
    "\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1Ez-FpSO7Jn"
   },
   "source": [
    "#1) API Installation & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG15pQfISqB1"
   },
   "outputs": [],
   "source": [
    "API_KEY = \"[**input api key]\"\n",
    "\n",
    "INPUT_FILE_NAME = \"/content/Cleaned data/2025_cleaned_data.csv\"\n",
    "SAVE_DIR = \"/content/Processed Data\"\n",
    "\n",
    "STREAM_FILE_NAME = \"2025_summaries_cache_stream.jsonl\"\n",
    "FINAL_FILE_NAME = \"2025_paper_summaries_final.json\"\n",
    "\n",
    "STREAM_FILE = os.path.join(SAVE_DIR, STREAM_FILE_NAME)\n",
    "FINAL_FILE = os.path.join(SAVE_DIR, FINAL_FILE_NAME)\n",
    "\n",
    "BATCH_SIZE = 20 # input 20 papers per batch\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "if not os.path.exists(INPUT_FILE_NAME):\n",
    "    print(\"CSV not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zG4aHD5dO-7G"
   },
   "source": [
    "#2) LLM Prompt and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hb2AOLc9TC7S"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are an academic research analyst. Extract structured metadata and provide balanced, objective summaries in English. Give equal weight to the research process and the findings. Output JSON only.\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Extract information in EXACT JSON format:\n",
    "{{\n",
    "  \"paper_id\": \"{paper_id}\",\n",
    "  \"title\": \"{title}\",\n",
    "  \"domain\": \"Primary research field\",\n",
    "  \"problem\": \"Context & Question: Describe the background or the gap in knowledge being addressed. (1-2 sentences)\",\n",
    "  \"methodology\": \"Research Approach: Detail the study design, subjects, and specific analytical steps. (1-2 sentences)\",\n",
    "  \"data_type\": \"Type of data analyzed\",\n",
    "  \"techniques_tools\": [\"Key analytical tools, software, or laboratory techniques\"],\n",
    "  \"key_concepts\": [\"3-5 core scientific concepts\"],\n",
    "  \"main_findings\": \"Observed Results: State the primary findings objectively based on evidence. (1-2 sentences)\",\n",
    "  \"summary_short\": \"Scientific Summary (English): Provide a cohesive, formal academic narrative. Ensure the 'How' (methodology) and the 'What' (outcomes) are balanced. End with its potential application or contribution to the field without overstating it.\",\n",
    "  \"summary_simple\": \"Simplified Explanation (English - Age 18): Explain the research logic for a high school senior. Describe the initial uncertainty, the steps taken by researchers, and the observed reality. Use 'Term (short explanation)' for jargon. Use formal yet accessible language.\",\n",
    "  \"practical_relevance\": \"Contextual Significance: State how this advances the field or contributes to fundamental knowledge.\",\n",
    "  \"data_quality_flag\": \"VALID\"\n",
    "}}\n",
    "\n",
    "Strict Rules:\n",
    "1. EXPLICIT INFO ONLY: Use ONLY information explicitly stated in the provided abstract. Do NOT guess or use outside knowledge.\n",
    "2. COMPARISON RULE: If the study involves comparison (e.g., A vs B, control vs experimental), explicitly state what was compared and which performed better or showed significant differences.\n",
    "3. INSUFFICIENT INFO: If information is insufficient for any specific field, state \"Not mentioned\".\n",
    "4. DATA QUALITY: If the abstract is missing, empty, or too short to provide a meaningful summary, set \"data_quality_flag\": \"INVALID_ABSTRACT\".\n",
    "5. LANGUAGE: All summary fields must be in ENGLISH.\n",
    "6. BALANCED WEIGHT: Ensure the methodology and results receive equal detail in the summaries. Do not overlook the research process.\n",
    "7. TONE: Use a professional, neutral, and descriptive tone. Avoid conversational fillers.\n",
    "8. JARGON: In 'summary_simple', always explain technical terms in parentheses immediately after.\n",
    "\n",
    "Paper Details:\n",
    "ID: {paper_id} | Title: {title}\n",
    "Abstract: {abstract}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxQrlBnRTLFF"
   },
   "outputs": [],
   "source": [
    "def call_openai_batch(batch_papers):\n",
    "    combined_prompt = \"Process these papers and return a JSON list of objects:\\n\\n\"\n",
    "    for p in batch_papers:\n",
    "        combined_prompt += USER_PROMPT_TEMPLATE.format(\n",
    "            paper_id=p['EID'], title=p['Title'], abstract=p['Abstract']\n",
    "        ) + \"\\n---\\n\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": combined_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        res_data = json.loads(response.choices[0].message.content)\n",
    "        for key in res_data:\n",
    "            if isinstance(res_data[key], list): return res_data[key]\n",
    "        return [res_data] if isinstance(res_data, dict) else []\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def append_to_jsonl(results, filename):\n",
    "    with open(filename, 'a', encoding='utf-8') as f:\n",
    "        for item in results:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPQlqsJSPEO-"
   },
   "source": [
    "#4) Run process and Download JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqJzDCUowoUd"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not API_KEY:\n",
    "        print(\"enter API Key to Step 1\"); return\n",
    "\n",
    "    if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)\n",
    "\n",
    "    df = pd.read_csv(INPUT_FILE_NAME).fillna(\"\")\n",
    "    done_ids = set()\n",
    "\n",
    "    if os.path.exists(STREAM_FILE):\n",
    "        with open(STREAM_FILE, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    d = json.loads(line)\n",
    "                    done_ids.add(str(d.get('paper_id')))\n",
    "                except: continue\n",
    "\n",
    "    to_process = [\n",
    "        {'EID': str(row['EID']), 'Title': row['Title'], 'Abstract': row['Abstract']}\n",
    "        for _, row in df.iterrows() if str(row['EID']) not in done_ids\n",
    "    ]\n",
    "\n",
    "    print(f\"ðŸ“Š à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {len(df)} | à¸—à¸³à¹à¸¥à¹‰à¸§: {len(done_ids)} | à¸£à¸­à¸„à¸´à¸§: {len(to_process)}\")\n",
    "\n",
    "    for i in range(0, len(to_process), BATCH_SIZE): # start the running process\n",
    "        batch = to_process[i:i+BATCH_SIZE]\n",
    "        print(f\"Proceeding Batch {i//BATCH_SIZE + 1}\")\n",
    "\n",
    "        batch_lookup = {str(p['EID']): p['Abstract'] for p in batch} # initiate the lookup\n",
    "\n",
    "        results = call_openai_batch(batch)\n",
    "        if results:\n",
    "            for item in results:\n",
    "                eid_key = str(item.get('paper_id'))\n",
    "                item['original_abstract'] = batch_lookup.get(eid_key, \"Abstract not found\")\n",
    "\n",
    "            append_to_jsonl(results, STREAM_FILE)\n",
    "            print(f\"Save batch {i//BATCH_SIZE + 1}\")\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    if os.path.exists(STREAM_FILE):\n",
    "        with open(STREAM_FILE, 'r', encoding='utf-8') as f:\n",
    "            final_list = [json.loads(line) for line in f]\n",
    "        with open(FINAL_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_list, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"final file is at: {FINAL_FILE}\")\n",
    "        files.download(FINAL_FILE)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}