{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this coding file, we aimed to **summarize the abstract and generate supplementary descriptions** based on the paper‚Äôs 'title' and 'abstract' fields, utilizing the ChatGPT-4o-mini model API. The final file is jsonl and json -> input for visualization as hover."
      ],
      "metadata": {
        "id": "P5r0QgccJYlA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG15pQfISqB1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1) API Installation & Settings\n",
        "\n",
        "!pip install -q openai pandas\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from openai import OpenAI\n",
        "from google.colab import files\n",
        "\n",
        "API_KEY = \"[**input api key]\"\n",
        "\n",
        "INPUT_FILE_NAME = \"/content/Cleaned data/2025_cleaned_data.csv\"\n",
        "SAVE_DIR = \"/content/Processed Data\"\n",
        "\n",
        "STREAM_FILE_NAME = \"2025_summaries_cache_stream.jsonl\"\n",
        "FINAL_FILE_NAME = \"2025_paper_summaries_final.json\"\n",
        "\n",
        "STREAM_FILE = os.path.join(SAVE_DIR, STREAM_FILE_NAME)\n",
        "FINAL_FILE = os.path.join(SAVE_DIR, FINAL_FILE_NAME)\n",
        "\n",
        "BATCH_SIZE = 20 # input 20 papers per batch\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "if not os.path.exists(INPUT_FILE_NAME):\n",
        "    print(\"CSV not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb2AOLc9TC7S",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2) LLM Prompt\n",
        "\n",
        "SYSTEM_PROMPT = \"You are an academic research analyst. Extract structured metadata and provide balanced, objective summaries in English. Give equal weight to the research process and the findings. Output JSON only.\"\n",
        "\n",
        "USER_PROMPT_TEMPLATE = \"\"\"\n",
        "Extract information in EXACT JSON format:\n",
        "{{\n",
        "  \"paper_id\": \"{paper_id}\",\n",
        "  \"title\": \"{title}\",\n",
        "  \"domain\": \"Primary research field\",\n",
        "  \"problem\": \"Context & Question: Describe the background or the gap in knowledge being addressed. (1-2 sentences)\",\n",
        "  \"methodology\": \"Research Approach: Detail the study design, subjects, and specific analytical steps. (1-2 sentences)\",\n",
        "  \"data_type\": \"Type of data analyzed\",\n",
        "  \"techniques_tools\": [\"Key analytical tools, software, or laboratory techniques\"],\n",
        "  \"key_concepts\": [\"3-5 core scientific concepts\"],\n",
        "  \"main_findings\": \"Observed Results: State the primary findings objectively based on evidence. (1-2 sentences)\",\n",
        "  \"summary_short\": \"Scientific Summary (English): Provide a cohesive, formal academic narrative. Ensure the 'How' (methodology) and the 'What' (outcomes) are balanced. End with its potential application or contribution to the field without overstating it.\",\n",
        "  \"summary_simple\": \"Simplified Explanation (English - Age 18): Explain the research logic for a high school senior. Describe the initial uncertainty, the steps taken by researchers, and the observed reality. Use 'Term (short explanation)' for jargon. Use formal yet accessible language.\",\n",
        "  \"practical_relevance\": \"Contextual Significance: State how this advances the field or contributes to fundamental knowledge.\",\n",
        "  \"data_quality_flag\": \"VALID\"\n",
        "}}\n",
        "\n",
        "Strict Rules:\n",
        "1. EXPLICIT INFO ONLY: Use ONLY information explicitly stated in the provided abstract. Do NOT guess or use outside knowledge.\n",
        "2. COMPARISON RULE: If the study involves comparison (e.g., A vs B, control vs experimental), explicitly state what was compared and which performed better or showed significant differences.\n",
        "3. INSUFFICIENT INFO: If information is insufficient for any specific field, state \"Not mentioned\".\n",
        "4. DATA QUALITY: If the abstract is missing, empty, or too short to provide a meaningful summary, set \"data_quality_flag\": \"INVALID_ABSTRACT\".\n",
        "5. LANGUAGE: All summary fields must be in ENGLISH.\n",
        "6. BALANCED WEIGHT: Ensure the methodology and results receive equal detail in the summaries. Do not overlook the research process.\n",
        "7. TONE: Use a professional, neutral, and descriptive tone. Avoid conversational fillers.\n",
        "8. JARGON: In 'summary_simple', always explain technical terms in parentheses immediately after.\n",
        "\n",
        "Paper Details:\n",
        "ID: {paper_id} | Title: {title}\n",
        "Abstract: {abstract}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxQrlBnRTLFF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3) Core Functions\n",
        "\n",
        "def call_openai_batch(batch_papers):\n",
        "    combined_prompt = \"Process these papers and return a JSON list of objects:\\n\\n\"\n",
        "    for p in batch_papers:\n",
        "        combined_prompt += USER_PROMPT_TEMPLATE.format(\n",
        "            paper_id=p['EID'], title=p['Title'], abstract=p['Abstract']\n",
        "        ) + \"\\n---\\n\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": combined_prompt}\n",
        "            ],\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        res_data = json.loads(response.choices[0].message.content)\n",
        "        for key in res_data:\n",
        "            if isinstance(res_data[key], list): return res_data[key]\n",
        "        return [res_data] if isinstance(res_data, dict) else []\n",
        "    except Exception as e:\n",
        "        print(f\"API Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def append_to_jsonl(results, filename):\n",
        "    with open(filename, 'a', encoding='utf-8') as f:\n",
        "        for item in results:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqJzDCUowoUd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 4) Run Process & Download JSON\n",
        "\n",
        "def main():\n",
        "    if not API_KEY:\n",
        "        print(\"enter API Key to Step 1\"); return\n",
        "\n",
        "    if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)\n",
        "\n",
        "    df = pd.read_csv(INPUT_FILE_NAME).fillna(\"\")\n",
        "    done_ids = set()\n",
        "\n",
        "    if os.path.exists(STREAM_FILE):\n",
        "        with open(STREAM_FILE, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    d = json.loads(line)\n",
        "                    done_ids.add(str(d.get('paper_id')))\n",
        "                except: continue\n",
        "\n",
        "    to_process = [\n",
        "        {'EID': str(row['EID']), 'Title': row['Title'], 'Abstract': row['Abstract']}\n",
        "        for _, row in df.iterrows() if str(row['EID']) not in done_ids\n",
        "    ]\n",
        "\n",
        "    print(f\"üìä ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df)} | ‡∏ó‡∏≥‡πÅ‡∏•‡πâ‡∏ß: {len(done_ids)} | ‡∏£‡∏≠‡∏Ñ‡∏¥‡∏ß: {len(to_process)}\")\n",
        "\n",
        "    for i in range(0, len(to_process), BATCH_SIZE): # start the running process\n",
        "        batch = to_process[i:i+BATCH_SIZE]\n",
        "        print(f\"Proceeding Batch {i//BATCH_SIZE + 1}\")\n",
        "\n",
        "        batch_lookup = {str(p['EID']): p['Abstract'] for p in batch} # initiate the lookup\n",
        "\n",
        "        results = call_openai_batch(batch)\n",
        "        if results:\n",
        "            for item in results:\n",
        "                eid_key = str(item.get('paper_id'))\n",
        "                item['original_abstract'] = batch_lookup.get(eid_key, \"Abstract not found\")\n",
        "\n",
        "            append_to_jsonl(results, STREAM_FILE)\n",
        "            print(f\"Save batch {i//BATCH_SIZE + 1}\")\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    if os.path.exists(STREAM_FILE):\n",
        "        with open(STREAM_FILE, 'r', encoding='utf-8') as f:\n",
        "            final_list = [json.loads(line) for line in f]\n",
        "        with open(FINAL_FILE, 'w', encoding='utf-8') as f:\n",
        "            json.dump(final_list, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"final file is at: {FINAL_FILE}\")\n",
        "        files.download(FINAL_FILE)\n",
        "\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}